# Drivers Analysis: AI Governance Landscape (2024-2030)

**Focal Question:** How will the global AI governance landscape evolve, and what are the implications for organizations developing or deploying AI systems?

---

## Driver Inventory

### Technological Drivers

#### T1: Frontier Model Capability Advancement

| Attribute | Assessment |
|-----------|------------|
| **Description** | Rate of improvement in frontier AI capabilities (reasoning, agency, multimodality) |
| **Current trend** | Rapid advancement; GPT-4 → o1 reasoning models in <2 years |
| **Direction** | Accelerating, though potential slowdowns debated |
| **Impact** | ⬤⬤⬤⬤⬤ Critical — drives both opportunity and risk calculus |
| **Uncertainty** | ⬤⬤⬤⬤○ High — scaling law limits unknown |
| **Time horizon** | Continuous; major capability jumps every 12-24 months |

#### T2: Agentic AI Deployment

| Attribute | Assessment |
|-----------|------------|
| **Description** | Proliferation of AI systems that take autonomous actions (browsing, coding, tool use) |
| **Current trend** | Early deployment; agents moving from demos to production |
| **Direction** | Expanding rapidly |
| **Impact** | ⬤⬤⬤⬤⬤ Critical — fundamentally changes risk profile |
| **Uncertainty** | ⬤⬤⬤○○ Medium — deployment is happening, scope unclear |
| **Time horizon** | 2024-2026 for mainstream adoption |

#### T3: Compute Concentration

| Attribute | Assessment |
|-----------|------------|
| **Description** | Geographic and corporate concentration of AI training compute |
| **Current trend** | Highly concentrated (US hyperscalers, NVIDIA) |
| **Direction** | Potential diversification via new fabs, or further concentration |
| **Impact** | ⬤⬤⬤⬤○ High — shapes who can build frontier systems |
| **Uncertainty** | ⬤⬤⬤⬤○ High — depends on industrial policy, geopolitics |
| **Time horizon** | 2025-2030 for new fab capacity |

#### T4: Open-Source Model Proliferation

| Attribute | Assessment |
|-----------|------------|
| **Description** | Availability of capable open-weight models (Llama, Mistral, etc.) |
| **Current trend** | Rapidly expanding; open models approaching frontier performance |
| **Direction** | Continued releases; gap to frontier narrowing |
| **Impact** | ⬤⬤⬤⬤○ High — democratizes capability, complicates control |
| **Uncertainty** | ⬤⬤⬤○○ Medium — major labs committed to open releases |
| **Time horizon** | Ongoing |

---

### Political/Regulatory Drivers

#### P1: US Federal AI Regulatory Posture

| Attribute | Assessment |
|-----------|------------|
| **Description** | Whether US pursues binding AI regulation vs. voluntary frameworks |
| **Current trend** | Shift toward deregulation; EO 14110 rescinded |
| **Direction** | Uncertain — depends on administration, events |
| **Impact** | ⬤⬤⬤⬤⬤ Critical — sets tone for global governance |
| **Uncertainty** | ⬤⬤⬤⬤⬤ Very high — politically contested |
| **Time horizon** | 2025-2028 |

#### P2: EU AI Act Implementation

| Attribute | Assessment |
|-----------|------------|
| **Description** | How strictly EU AI Act is interpreted and enforced |
| **Current trend** | Act passed; implementation beginning |
| **Direction** | Enforcement ramping up 2025-2027 |
| **Impact** | ⬤⬤⬤⬤○ High — creates compliance baseline for global firms |
| **Uncertainty** | ⬤⬤⬤○○ Medium — law exists, enforcement approach unclear |
| **Time horizon** | 2025-2027 |

#### P3: US-China AI Competition

| Attribute | Assessment |
|-----------|------------|
| **Description** | Intensity of strategic competition in AI capabilities and governance |
| **Current trend** | Escalating; export controls, compute restrictions |
| **Direction** | Likely continued escalation |
| **Impact** | ⬤⬤⬤⬤⬤ Critical — shapes global AI architecture |
| **Uncertainty** | ⬤⬤⬤○○ Medium — trajectory clear, specifics uncertain |
| **Time horizon** | Ongoing |

#### P4: International Governance Coordination

| Attribute | Assessment |
|-----------|------------|
| **Description** | Whether international AI governance frameworks emerge (UN, G7, bilateral) |
| **Current trend** | Early efforts (Bletchley, Seoul summits); limited binding commitments |
| **Direction** | Unclear — momentum but no consensus |
| **Impact** | ⬤⬤⬤○○ Medium — could shape norms if achieved |
| **Uncertainty** | ⬤⬤⬤⬤⬤ Very high — depends on geopolitics |
| **Time horizon** | 2025-2030 |

---

### Economic Drivers

#### E1: AI Investment Levels

| Attribute | Assessment |
|-----------|------------|
| **Description** | Capital flowing into AI development and deployment |
| **Current trend** | Massive; $200B+ annually across big tech and startups |
| **Direction** | Sustained high investment, some concentration |
| **Impact** | ⬤⬤⬤⬤○ High — determines pace of capability development |
| **Uncertainty** | ⬤⬤⬤○○ Medium — investor enthusiasm high, corrections possible |
| **Time horizon** | Ongoing |

#### E2: Automation-Driven Labor Displacement

| Attribute | Assessment |
|-----------|------------|
| **Description** | Rate and scope of job displacement from AI automation |
| **Current trend** | Early impacts in specific sectors (coding, customer service, content) |
| **Direction** | Expanding, pace uncertain |
| **Impact** | ⬤⬤⬤⬤⬤ Critical — drives political response |
| **Uncertainty** | ⬤⬤⬤⬤○ High — depends on capability + adoption speed |
| **Time horizon** | 2025-2030 |

---

### Social Drivers

#### S1: Public Trust in AI

| Attribute | Assessment |
|-----------|------------|
| **Description** | General population attitudes toward AI safety and benefits |
| **Current trend** | Mixed; awareness increasing, trust fragmented |
| **Direction** | Uncertain — depends on high-profile incidents |
| **Impact** | ⬤⬤⬤○○ Medium — influences political feasibility of regulation |
| **Uncertainty** | ⬤⬤⬤⬤○ High — could shift rapidly with major event |
| **Time horizon** | Ongoing |

#### S2: AI Safety Research Community Influence

| Attribute | Assessment |
|-----------|------------|
| **Description** | Influence of AI safety researchers on lab priorities and governance |
| **Current trend** | Significant but contested; departures from labs, public debates |
| **Direction** | Uncertain — either mainstreaming or marginalization |
| **Impact** | ⬤⬤⬤⬤○ High — shapes how labs self-govern |
| **Uncertainty** | ⬤⬤⬤⬤○ High — depends on incidents, lab leadership |
| **Time horizon** | Ongoing |

---

## Driver Prioritization Matrix

| Driver | Impact (1-5) | Uncertainty (1-5) | Priority |
|--------|--------------|-------------------|----------|
| T1: Frontier capabilities | 5 | 4 | **Critical** |
| T2: Agentic AI | 5 | 3 | **Critical** |
| P1: US regulatory posture | 5 | 5 | **Critical** |
| P3: US-China competition | 5 | 3 | **High** |
| E2: Labor displacement | 5 | 4 | **Critical** |
| P2: EU AI Act implementation | 4 | 3 | **High** |
| T3: Compute concentration | 4 | 4 | **High** |
| T4: Open-source proliferation | 4 | 3 | **High** |
| P4: International coordination | 3 | 5 | **Monitor** |
| E1: Investment levels | 4 | 3 | **High** |
| S1: Public trust | 3 | 4 | **Monitor** |
| S2: Safety community influence | 4 | 4 | **High** |

---

## Selected Critical Uncertainties

Based on this analysis, the two highest-impact, highest-uncertainty drivers are:

1. **AI Capability Trajectory:** Incremental improvement ↔ Discontinuous leap
2. **Global Regulatory Coherence:** Fragmented national approaches ↔ Harmonized international framework

These form the axes for scenario development. See `uncertainties.md`.
