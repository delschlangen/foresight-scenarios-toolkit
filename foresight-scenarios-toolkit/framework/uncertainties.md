# Critical Uncertainties

Two critical uncertainties selected from driver analysis to form scenario axes.

---

## Axis 1: AI Capability Trajectory

**Spectrum:** Incremental Improvement ↔ Discontinuous Leap

### Incremental Improvement (Left)

AI capabilities continue advancing but follow predictable scaling patterns. No fundamental breakthroughs occur. Progress is steady, measurable, and allows institutions time to adapt.

**Characteristics:**
- Scaling laws continue but with diminishing returns
- New capabilities emerge gradually over 2-3 year cycles
- No "GPT-5 moment" that fundamentally changes the landscape
- Current approaches (transformers, RLHF) remain dominant
- Human expertise remains essential for most high-stakes domains

**Implications:**
- Regulatory frameworks can keep pace
- Labor market adjusts through normal retraining
- Existing governance approaches remain adequate
- Safety research has time to mature

### Discontinuous Leap (Right)

A fundamental breakthrough occurs—whether through architectural innovation, recursive self-improvement, or emergent capabilities—that dramatically accelerates the timeline.

**Characteristics:**
- Rapid capability gains (months, not years)
- Emergence of capabilities not predicted by scaling
- Autonomous AI systems that meaningfully self-improve
- Human oversight becomes technically difficult
- Economic disruption happens faster than adaptation

**Implications:**
- Existing regulatory frameworks become obsolete overnight
- Labor displacement outpaces social safety nets
- Safety research is outrun by capabilities
- First-mover advantages become decisive

---

## Axis 2: Global Regulatory Coherence

**Spectrum:** Fragmented National Approaches ↔ Harmonized International Framework

### Fragmented National Approaches (Bottom)

Countries pursue divergent AI governance strategies based on national interests, values, and competitive positioning. No meaningful international coordination emerges.

**Characteristics:**
- EU pursues strict precautionary regulation
- US pursues minimal federal intervention
- China pursues state-directed development with controls
- Regulatory arbitrage flourishes
- Global companies face compliance patchwork
- "Race to the bottom" dynamics in some jurisdictions

**Implications:**
- Multinational deployment is complex/costly
- Safety standards vary dramatically
- Difficult to address global-scale risks
- Innovation concentrates in permissive jurisdictions

### Harmonized International Framework (Top)

Major powers achieve meaningful coordination on AI governance through treaties, standards bodies, or mutual recognition agreements.

**Characteristics:**
- Baseline safety requirements accepted globally
- Mutual recognition of compliance certifications
- Coordinated approach to frontier AI oversight
- Shared incident reporting and response
- Compute governance coordination

**Implications:**
- Clearer compliance pathway for global companies
- Reduced race-to-the-bottom pressure
- Better positioned to address global risks
- May slow innovation in some areas

---

## Axis Selection Rationale

### Why these two axes?

| Criterion | Axis 1: Capability | Axis 2: Regulation |
|-----------|-------------------|-------------------|
| Impact | Drives everything else | Determines response options |
| Uncertainty | Genuine unknown | Politically contested |
| Independence | Technology vs. politics | Relatively uncorrelated |
| Differentiation | Creates very different worlds | Shapes how worlds are managed |

### Alternative axes considered but rejected

| Axis | Reason Rejected |
|------|-----------------|
| Open vs. Closed source dominance | Somewhat correlated with regulation axis |
| High vs. Low public trust | More effect than cause |
| US vs. China leadership | Subsumed under regulation axis |
| Major AI incident vs. None | Too binary; better as scenario trigger |

---

## Scenario Matrix Preview

```
                    HARMONIZED REGULATION
                           ▲
                           │
         ┌─────────────────┼─────────────────┐
         │                 │                 │
         │   "Coordinated  │   "Emergency    │
         │    Caution"     │   Coordination" │
         │                 │                 │
INCREMENTAL ◄──────────────┼────────────────► DISCONTINUOUS
CAPABILITY                 │                   CAPABILITY
         │                 │                 │
         │   "Patchwork    │   "Fragmented   │
         │    Progress"    │    Scramble"    │
         │                 │                 │
         └─────────────────┼─────────────────┘
                           │
                           ▼
                    FRAGMENTED REGULATION
```

See `scenarios.md` for full scenario narratives.
